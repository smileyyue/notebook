[TOC]

# 数据结构

## 队列

### 单向队列

### 双向队列

### 优先队列

优先队列容器与队列一样，只能从队尾插入元素，从队首删除元素。但是它有一个特性，就是队列中最大的元素总是位于队首，所以出队时，并非按照先进先出的原则进行，而是将当前队列中最大的元素出队。这点类似于给队列里的元素进行了由大到小的顺序排序。元素的比较规则默认按元素值由大到小排序，可以重载“<”操作符来重新定义比较规则。

STL的优先队列：`#include <queue>`

基本操作：

``` cpp
priority_queue<int> q;								  //通过操作，按照元素从大到小的顺序出队
priority_queue<int,vector<int>, greater<int> > q;	  //通过操作，按照元素从小到大的顺序出队
empty();  	//如果队列为空，则返回真
pop();		//删除对顶元素，删除第一个元素
push();		//加入一个元素
size();		//返回优先队列中拥有的元素个数
top();		//返回优先队列对顶元素，返回优先队列中有最高优先级的元素
```

优先队列可以用堆来实现。

## 树

自由树：连通的，无回路的无向图。

二叉树：结点最大度数为2的树，子树由左右之分不能颠倒。

满二叉树：深度为k，且由$2^{k-1}$个结点的树（另可定义为：除了叶结点外每个结点都有左右子叶且叶结点都处于最底层的二叉树）。满二叉树标准形态如下（严格的三角形）：

![满二叉树](http://img.blog.csdn.net/20130909225615687?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvY2hlbmdtYW9uaW5n/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center)

完全二叉树：类似满二叉树，但最底层叶结点不全，且有的叶结点在左侧连续的二叉树。满二叉树是一种特殊的完全二叉树。标准形态如下：

![完全二叉树](http://img.blog.csdn.net/20130909225741093?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvY2hlbmdtYW9uaW5n/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)

完全二叉树的特点是：“叶子节点的位置比较规律”。因此在对数据进行排序或者查找时可以用到它，比如堆排序就使用了它。

二叉搜索树：

- 定义：
  - 若左子树不空，则左子树上所有结点的值均小于它的根结点的值；
  - 若右子树不空，则右子树上所有结点的值均大于或等于它的根结点的值；
  - 左、右子树也分别为二叉排序树。
- 二叉搜索树的中序遍历一定是从小到达的；
- 插入、查找的时间复杂度：最好：完全二叉树$O(\log_2 n)$，最差：插入有序变成链表$O(n)$
- 插入有序元素是不好控制让其不成链表，此时要用平衡二叉树；

平衡二叉树(AVL树)：

- 定义：
  - 平衡二叉树要么是一棵空树
  - 要么保证左右子树的高度之差不大于 1
  - 子树也必须是一颗平衡二叉树
- AVL树解决了二叉搜索树退化成链表的问题；
  - 把插入，查找，删除的时间复杂度最好情况和最坏情况都维持在O(logN)；
  - 但是频繁旋转会使插入和删除牺牲掉O(logN)左右的时间，不过相对二叉查找树来说，时间上稳定了很多。
- AVL树的旋转：
  - AVL树通过旋转来使树保持平衡状态，当进行插入、删除工作后，需要计算平衡因子，然后有需要则重新平衡二叉树；
  - 树堆旋转有四种方式：LL旋转，RR旋转，LR旋转，RL旋转，RR和LL是单旋转，RL和LR是双旋转；
  - 平衡因子BF计算：插入时计算所在子树高度变化即可

### 红黑树

参考文献：

- 

定义：

1. 每个结点或是红色的，或是黑色的
2. 根节点是黑色的
3. 每个叶结点（NIL）是黑色的
4. 如果一个节点是红色的，则它的两个儿子都是黑色的。
5. 对于每个结点，从该结点到其子孙结点的所有路径上包含相同数目的黑色结点。

引理：一棵有n个内结点的红黑树的高度至多为2lg(n+1)。

- 对以x为根的子树，它所包含的内部结点数至少为2^[bh(x)]-1。这里bh(x)（bh，black height）被定义为结点x的黑高度，就是说，从结点x（不包括它本身）到它任一个叶结点的路径上所有黑色结点的个数。 
- 一颗红黑树黑色结点数目是红色的两倍；

插入：

- 默认插入红色结点，因为黑色结点时红色的两倍，所以插入红色结点不用调整的概率较大；
- 插入结点后检测红黑树状态，如果父节点时黑色，则不影响平衡，插入完成；
- 如果父节点是红色则要进行变色或左右旋转操作，然后迭代往上检查到根节点。

红黑树的特点：

- 比AVL效率高，因为AVL树每次插入后都需要检测或调整，而红黑树如果父节点为黑则不用检测调整，且红色结点少，需要调整的次数少很多；

## 堆

[堆和树的区别](https://blog.csdn.net/lifei128/article/details/82392940)：堆的子节点都小于各自的父节点，一层比一层小，同级之间无顺序、不同级不同子树之间无顺序（最大堆是这样，最小堆反过来）。树则不一定。

堆heap和树tree的结合：树堆(treap)，每个节点由两个值value和weight，weight满足二叉堆特性（父比子都大/小），value满足排序二叉树特性（左<根<右），value要维护，weight则是随机生成的值，随机生成的weight使得treap变得平衡，所以treap是一种短小精悍的平衡树的实现。

堆可以当作优先队列使用。

- 优先队列支持以下操作
  - 放一个元素进去
  - 总是能取出一个最大的元素出来(大，小的规矩可以通过一个比较函数来定义)
- 显然堆就是可以这么做。

## 哈希表

### 参考链接：

- [wiki百科](https://zh.wikipedia.org/wiki/%E5%93%88%E5%B8%8C%E8%A1%A8)
- [哈希表和哈希桶](https://blog.csdn.net/wm12345645/article/details/80329944)
  - [hash函数应用（整理）](https://blog.csdn.net/szu_tanglanting/article/details/12406605)

### 定义

#### 散列表（Hash table，也叫哈希表）

哈希表是根据键（Key）而直接访问在内存存储位置的数据结构。也就是说，它通过计算一个关于键值的函数，将所需查询的数据映射到表中一个位置来访问记录，这加快了查找速度。这个映射函数称做散列函数，存放记录的数组称做散列表。

>  即通过key值和哈希函数hash()，得到存放value的目标地址addr=hash(key)，这样(key,value)的value就存放在了addr指向的地址中。

#### 冲突(Collision)

$k_1 \ne k_2​$但$f(k_1) = f(k_2)​$ 则发生了冲突，两个不同的key指向同一个地址。

#### 载荷因子

散列表的载荷因子定义为：$\alpha= \frac{填入表中的元素个数}{散列表的长度}$

$\alpha​$是散列表装满程度的标志因子。由于表长是定值，$ \alpha​$与“填入表中的元素个数”成正比，所以，$\alpha​$越大，表明填入表中的元素越多，产生冲突的可能性就越大；反之，$\alpha ​$越小，标明填入表中的元素越少，产生冲突的可能性就越小。实际上，散列表的平均查找长度是载荷因子$\alpha​$的函数，只是不同处理冲突的方法有不同的函数。

对于开放定址法，荷载因子是特别重要因素，应严格限制在0.7-0.8以下。超过0.8，查表时的CPU缓存不命中（cache missing）按照指数曲线上升。因此，一些采用开放定址法的hash库，如Java的系统库限制了荷载因子为0.75，超过此值将resize散列表。

### 散列函数构造方法

- 直接定址法：取关键字或关键字的某个线性函数值为散列地址。即$hash(k)=k​$或$hash(k)=a\cdot k+b​$，其中$a\,b​$为常数（这种散列函数叫做自身函数）
- 数字分析法：假设关键字是以r为基的数，并且哈希表中可能出现的关键字都是事先知道的，则可取关键字的若干数位组成哈希地址。
- 平方取中法：取关键字平方后的中间几位为哈希地址。通常在选定哈希函数时不一定能知道关键字的全部情况，取其中的哪几位也不一定合适，而一个数平方后的中间几位数和数的每一位都相关，由此使随机分布的关键字得到的哈希地址也是随机的。取的位数由表长决定。
- 折叠法：将关键字分割成位数相同的几部分（最后一部分的位数可以不同），然后取这几部分的叠加和（舍去进位）作为哈希地址。
- 随机数法
- 除留余数法：取关键字被某个不大于散列表表长m的数p除后所得的余数为散列地址。即$hash(k)=k \mod p,p\leq m$。不仅可以对关键字直接取模，也可在折叠法、平方取中法等运算之后取模。对p的选择很重要，一般取素数或m，若p选择不好，容易产生冲突。

### 冲突处理方法

- 开放定址法：线性探测和平方探测，这种探测会有时探测到一连串被用过的空间，这串空间被称作：聚集(Cluster，又称堆积)，聚集会造成开放定址法的性能灾难性损失，浪费时间。
- 单独链表法(又称哈希桶，hash slot）：**常用**，将散列到同一个存储位置的所有元素保存在一个链表中。实现时，一种策略是散列表同一位置的所有冲突结果都是用栈存放的，新元素被插入到表的前端还是后端完全取决于怎样方便。一个链表被称作一个桶

- 双散列。

- 再散列：$hash{i}=hash{i}(key), i=1,2...k$。$hash{i}$是一些散列函数。即在上次散列计算发生冲突时，利用该次冲突的散列函数地址产生新的散列函数地址，直到冲突不再发生。这种方法不易产生“聚集”（Cluster），但增加了计算时间。

- 建立一个公共溢出区

> 一般使用素数作为除数等用来计算，素数的冲突概率小很多

### 查找效率

查找过程中，关键码的比较次数，取决于产生冲突的多少，产生的冲突少，查找效率就高，产生的冲突多，查找效率就低。因此，影响产生冲突多少的因素，也就是影响查找效率的因素。影响产生冲突多少有以下三个因素：

1. 散列函数是否均匀；
2. 处理冲突的方法；
3. 散列表的载荷因子（英语：load factor）。

### hash函数优劣评估指标

1. 散列分布性：即桶的使用率backet_usage = (已使用桶数) / (总的桶数)，这个比例越高，说明分布性良好，是好的hash设计。
2. 平均桶长：即avg_backet_len，所有已使用桶的平均长度。理想状态下这个值应该=1，越小说明冲突发生地越少，是好的hash设计。

### 例程

#### 参考文献2例程节选

hash表结构体：

``` cpp
enum State//每个位置都有自己的状态
{
   EXIST,//存在的
   EMPTY,//可用的
   DELETE//被删除的
};
 
typedef struct KVP
{
  DataType value;//存储的值
  enum State state;//位置的状态
  int order;//顺序
  
}KVP;
 
 
typedef struct HashTable
{
   KVP *array;
   int  size;//有效容量
   int capacity;//容量
   int total;//已用容量（包括EXIST,DELETE）
   explore exp;//函数指针
}HashTable;
```

哈希函数：采用除数余留法，除数是哈希表的容量，而容量则选择素数

``` cpp
//int哈希函数
int HashFunc(int  capacity,DataType data)
{
	return  data%capacity;
}
//字符哈希函数
static size_t BKDRHash(const char * str)
{
    unsigned int seed = 131; // 31 131 1313 13131 131313
    unsigned int hash = 0;
    while (*str )
    {
        hash = hash * seed + (*str++);
    }
    return hash;
}
```

扩容函数：

``` cpp
//扩容
void AddCapacity(HashTable *ph)
{
  int i=0;
 
  HashTable NewHt;
  int NewN;
  assert(ph);
  if(ph->total*10/ph->capacity>=7)//乘10 是为了避免浮点数的问题，当已用元素个数占用总元素个数的70%以上时
  {
	  NewN=GetNextPrimeNum(ph->capacity);//这个函数的作用是：得到离ph->capacity最近的一个素数，一般比它大
	  InitHashTable(&NewHt,doub,NewN);
	  for(;i<ph->capacity;i++)
	  {
		  if(ph->array[i].state==EXIST)
		  {
			  InsertHashTable(&NewHt,ph->array[i].value);
		  }
	  }
	  swap(&NewHt,ph);
	  DestroyHashTable (&NewHt);
 
  }
}

void AddCapacity(HashTable *ph)
{
  int i=0;
 
  HashTable NewHt;
  int NewN;
  assert(ph);
  if(ph->total*10/ph->capacity>=7)//乘10 是为了避免浮点数的问题，当已用元素个数占用总元素个数的70%以上时
  {
	  NewN=GetNextPrimeNum(ph->capacity);//这个函数的作用是：得到离ph->capacity最近的一个素数，一般比它大
	  InitHashTable(&NewHt,doub,NewN);
	  for(;i<ph->capacity;i++)
	  {
		  if(ph->array[i].state==EXIST)
		  {
			  InsertHashTable(&NewHt,ph->array[i].value);
		  }
	  }
	  swap(&NewHt,ph);
	  DestroyHashTable (&NewHt);

  }
}
```

容量选择（即选择合适的素数）：

``` cpp
//得到最近的一个素数
int GetNextPrimeNum(int cur)
{
  int i=0;
  const int _PrimeSize=28;
  static const  long _PrimeList [28] =
 {
	 10ul, 97ul, 193ul, 389ul, 769ul,
	 1543ul, 3079ul, 6151ul, 12289ul, 24593ul,
	 49157ul, 98317ul, 196613ul, 393241ul, 786433ul,
	 1572869ul, 3145739ul, 6291469ul, 12582917ul, 25165843ul,
	 50331653ul, 100663319ul, 201326611ul, 402653189ul, 805306457ul,
	 1610612741ul, 3221225473ul, 4294967291ul
 }; 
  for(;i<_PrimeSize;i++)
  {
	  if(_PrimeList[i]>cur)//是否可以相等
	  {
	    return _PrimeList[i];
	  }
  }	  
  return _PrimeList [_PrimeSize-1];
```

#### linux hash实现

hash_long在<linux/hash.h>中定义如下:

``` c
/* 2^31 + 2^29 - 2^25 + 2^22 - 2^19 - 2^16 + 1 */
#define GOLDEN_RATIO_PRIME_32 0x9e370001UL
/*  2^63 + 2^61 - 2^57 + 2^54 - 2^51 - 2^18 + 1 */
#define GOLDEN_RATIO_PRIME_64 0x9e37fffffffc0001UL
 
#if BITS_PER_LONG == 32
#define GOLDEN_RATIO_PRIME GOLDEN_RATIO_PRIME_32
#define hash_long(val, bits) hash_32(val, bits)
#elif BITS_PER_LONG == 64
#define hash_long(val, bits) hash_64(val, bits)
#define GOLDEN_RATIO_PRIME GOLDEN_RATIO_PRIME_64
#else
#error Wordsize not 32 or 64
#endif
 
static inline u64 hash_64(u64 val, unsigned int bits)
{
    u64 hash = val;
 
    /*  Sigh, gcc can't optimise this alone like it does for 32 bits. */
    u64 n = hash;
    n <<= 18;
    hash -= n;
    n <<= 33;
    hash -= n;
    n <<= 3;
    hash += n;
    n <<= 3;
    hash -= n;
    n <<= 4;
    hash += n;
    n <<= 2;
    hash += n;
 
    /* High bits are more random, so use them. */
    return hash >> (64 - bits);
}
 
static inline u32 hash_32(u32 val, unsigned int bits)
{
    /* On some cpus multiply is faster, on others gcc will do shifts */
    u32 hash = val * GOLDEN_RATIO_PRIME_32;
 
    /* High bits are more random, so use them. */
    return hash >> (32 - bits);
}
 
static inline unsigned long hash_ptr(const void *ptr, unsigned int bits)
{
    return hash_long((unsigned long)ptr, bits);
}
#endif /* _LINUX_HASH_H */
```

首先，hash的方式是，让key乘以一个大数，于是结果溢出，就把留在32/64位变量中的值作为hash值，又由于散列表的索引长度有限，我们就取这hash值的高几为作为索引值，之所以取高几位，是因为高位的数更具有随机性，能够减少所谓“冲突”。什么是冲突呢？从上面的算法来看，key和hash值并不是一一对应的。有可能两个key算出来得到同一个hash值，这就称为“冲突”。

那么，乘以的这个大数应该是多少呢？从上面的代码来看，32位系统中这个数是0x9e370001UL，64位系统中这个数是0x9e37fffffffc0001UL。这个数是怎么得到的呢？

>  这个值接近黄金分割术会使得hash的结果最好，实际中linux内核选取的这两个值都是接近黄金分割数并且容易计算的。

“Knuth建议，要得到满意的结果，对于32位机器，2^32做黄金分割，这个大数是最接近黄金分割点的素数，0x9e370001UL就是接近 2^32*(sqrt(5)-1)/2 的一个素数，且这个数可以很方便地通过加运算和位移运算得到，因为它等于2^31 + 2^29 - 2^25 + 2^22 - 2^19 - 2^16 + 1。对于64位系统，这个数是0x9e37fffffffc0001UL，同样有2^63 + 2^61 - 2^57 + 2^54 - 2^51 - 2^18 + 1。”

从程序中可以看到，对于32位系统计算hash值是直接用的乘法，因为gcc在编译时会自动优化算法。而对于64位系统，gcc似乎没有类似的优化，所以用的是位移运算和加运算来计算。首先n=hash, 然后n左移18位，hash-=n，这样hash = hash * (1 - 2^18)，下一项是-2^51，而n之前已经左移过18位了，所以只需要再左移33位，于是有n <<= 33，依次类推，最终算出了hash值。

- 

# 算法

##  查找与排序

### 二分查找

适用范围：在已排序的数组中查找（部分排序也可，例如旋转数组）

时间复杂度：O(logn)

注意事项：

- mid = start + (end-start)/2;  等价于 mid = (start+end)/2;  用第二种较好
- mid已经判断过了就不要重复判断了，`start = mid + 1; end = mid - 1;`，以免陷入死循环
- 终止条件为while(start<end);
- 使用闭区间[start, end]，否则如果最终没找到停在开区间的边界，会造成数组越界；

### 堆排序

对于一个乱序数组，先建立最小（大）堆，然后循环提取根节点、重排堆，将根节点值依次放入新数组，就得到了排序数组。

特点：

- 时间复杂度：稳定的$O(n\log n)​$；
- 空间复杂度：$O(2n)$
- 排序时间复杂度与快排平均值相同，但要用额外空间，所以一般不用堆排序；
- 堆排序用于需要频繁较大值或较小值取出插入操作的时候，这是堆排序效率更高。

#### 最小堆

根节点是最小值，且每个子树根节点都是该子树最小值的树。

特点：

- 插入节点时间复杂度：$O(\log n)$，从叶节点开始比较，一层层上浮；
- 建堆时间复杂度：$O(n\log n)​$，n个节点插入，n*插入一个节点时间复杂度；

#### STL实现堆排序

参考文献：[STL之heap操作](https://www.cnblogs.com/helloworld-c/p/4854463.html)

前提：

- 使用vector库和algorithm库；
- 自建compare函数设置大小判断；

``` cpp
#include <vector>
#include <algorithm>	// 提供make_heap(), push_heap(), pop_heap()函数
// 比较函数
bool compare(int x, int y){
    return x>y;		// 最小堆：x>y，最大堆x<y
}
// 建堆
vector<int> heap;
make_heap(heap.begin(), heap.end(), compare);
// 插入
heap.push_back(num);
push_heap(heap.begin(), heap.end(), compare);
// 删除
pop_heap(heap.begin(),heap.end(),compare)；	// pop会把根节点（最大或最小值）放到数组最后
heap.pop_back()
```

### [Bit Map算法](https://www.cnblogs.com/protected/p/6626447.html)

Bit Map用于处理大数据量、小内存、无重复数据的排序问题。

Bit Map是用1bit表示一个数据，如：4：把第5位置1，7：把第8位之一，然后遍历位图，即可排序；

- 1G内存，存放数据，一个数据1Byte则大概能存放10亿数据，或可存2.5亿个int数据；
- 而使用位图的话，1Byte可以存8个数据(int也可)，1G内存可存80亿数据；
- 位图只用遍历一遍排序，再遍历一遍输出，时间效率O(2n)， 空间效率O(8/n)；

扩展：

- 使用位图后，内存够装下全部数据：直接做位图即可；

- 装不下：分块装入。

  > 找不存在的数：分块如分成1000个一块，每个数属于各块对各块计数+1，最后哪块计数不满1000则装入位图然后找不存在的那个。
  >
  > 找重复的数：2bit map，用2bit表示一个数，任何一个数的bit计数为2则重复，为1则单一存在，为0则不存在。

- 布隆过滤器(Bloom Fliter)：去重，判断目标是否已存在于表中，比哈希表更高效；

  - 布隆过滤器通过多种不同的hash函数，将一个key映射到多个bit；
  - 特点是高效地插入和查询，空间占用少，但删除麻烦；
  - 布隆过滤器是概率性数据结构，返回值结果只是说明目标可能存在而不是一定存在，但返回不存在就是绝对不存在。
  - 布隆过滤器的长度越长越好，过小的布隆过滤器，所有bit都是1则查询任何值都返回可能存在，起不到过滤的目的，布隆过滤器的长度会影响误报率。



## 动态规划

本质是对递归回溯的优化，递归回溯是从上到下的，动态规划是从下到上的，并且通过额外的内存空间记录已经计算过的值，保留做以后用，同时比较局部的各值，只留下最优的用于之后的比较。

动态规划的使用前提：

1. 是一个求最优解的问题；
2. 可以分成若干个更小的求最优解的问题，若干个更小的最优解中最优的一个是大问题的最优解；
3. 小问题之间还有相互重叠的更小子问题；
4. DAG的无环路径问题；

动态规划的思考方法：

1. 从上往下分析，从下往上求解；
2. 可以选个小的问题，自己推一推试试，记录中间变量；
3. 思考大问题能如何划分成小问题，然后再去考虑状态转移方程；

动态规划的时间复杂度：

- 线性问题的时间复杂度为$O(n)​$(d[i]仅与d[i-1]或d[i-1]和d[i-2]等有限个前量有关)，  $O(n^2)​$（d[i]与d[i-1]~d[1]全体有关，此时要做第二层循环for i=1~i-1，所以是$n^2​$）

## 贪心算法

贪心算法和动态规划的区别：

- 动态规划是把大问题分成小问题，然后根据各个小问题最优解得出大问题的最优解，如果小问题的最优解不是大问题的最优解，会找其他小问题的解，找到大问题的最优解。
- 而贪心算法是直接找最小问题的局部最优解，并直接把局部最优解当作全局最优解去继续求解。

例如：3， 5，10，50，100元纸币中挑出285元，则贪心算法直接从最大的找满，继续往下找到3元为止，结果是$100*2+50*1+10*3+5*1=285$，这是对的，但如果挑出286元，则贪心算法结果也是$100*2+50*1+10*3+5*1=285​$，答案是错的，最后应该用两张3元，而不是一张5元。如果最小面额是1元则可以用贪心算法，最小是3就要用动态规划了。

> 贪心算法可以用来求近似最优解，因为贪心算法的时间复杂度和空间复杂度都是$O(1)​$；
>
> 使用贪心算法时，一定要通过数学证明局部最优解是全局最优解，才能使用。

## 位运算

位运算效率高，可用于抠细节效率，例如：求奇偶`(x&1) == 0`，除$2^n$：`x>>n`

注意：

与或位运算符的优先级低于大于小于。所以`x&1 == 0`是错的，必须`(x&1) == 0`