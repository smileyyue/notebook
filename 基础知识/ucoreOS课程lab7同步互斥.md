# ucoreOS课程lab7同步互斥

[TOC]

## 原子锁定义

### 概述

基本同步方法：

``` mermaid
graph BT
硬件支持: --> B[高层抽象:]
B --> 并发编程:
禁用中断 --> A[信号量 锁 条件变量]
原子操作,如:TS指令 --> A
软件方法,原子load/store --> A
A --> C[临界区 管程]
```

并发进程：

- 并发进程的正确性：并发进程资源共享，有不确定性（输入状态不能决定结果，中间会受到干扰）和不可重现（起始条件不可重现，可能不一致）的特点。
- 并发执行的好处：共享资源、处理加速（多CPU并发执行，CPU&IO并行处理）、模块化（大程序拆分成小程序合作，使系统易于复用和扩展，例如编译：gcc调用cpp,cc1,cc2,as,ld等程序。

原子操作：

- 原子操作：一次不存在任何中断或失败的操作，一次连续执行不可被调度打断的操作。

  > 操作系统需要利用同步机制在并发执行的同时，保证一些操作是原子操作

- 原子锁：解决资源共享问题，锁定和解锁操作都是原子操作。

进程相互感知：

- 互相不感知，
- 间接感知（通过第三方交互），
- 直接感知（双方直接交互）

可能遇到的问题：

- 互斥(mutual exclusion)：一个进程占用资源其他进程不能使用；
- 死锁(deadlock)：几个进程各自占用部分资源，都不够完成工作，都不释放，陷入死循环等待；
- 饥饿(starvation)：一个进程优先级过低，一直得不到资源。

临界区：

- 临界区(critical section)：进程中访问临界资源的一段需要互斥执行的代码，临界区是位于上锁和解锁中间的代码。
- 进入区(entry section)：临界区前的一段代码，检查可否进入临界区的一段代码，如可进入设置相应“正在访问临界区”标志。
- 退出区(exitsection)：临界区后的一段代码，清除“正在访问临界区”标志。
- 剩余区(remainder section)：代码中其余部分。

临界区访问规则：

- 空闲则入：没进程在临界区，任何进程均可进入；
- 忙则等待：有进程在临界区，其他进程均不能进入；
- 有限等待：等待进入临界区的进程不能无限期的等待，等待时间有约定；
- 让权等待（可选）：不能进入临界区的进程，应释放CPU，阻塞等待，不能轮询。

## 临界区实现方法

### 禁用中断

- 此时没有时钟中断、没有上下文切换、没有并发，单一进程执行。
- 整个系统都会停下来，其他进程可能饥饿，临界区可能执行很长时间；
- 一般只在极重要场合使用，例如内核中做一些原子操作时，都是操作系统开发者能确定的临界区较短且必要的时候，不提供给用户程序用。
- 仅适用于单处理机。

### 软件方法

共享变量协调，不依靠硬件或者操作系统支持；

软件方法很复杂，轮询浪费CPU时间；

#### peterson算法（两进程同步）

``` c
// 共享变量
int turn;		// 表示轮到谁进入临界区
bool flag[];	// 表示进程是否准备进入临界区，或者说进程是否想要进入临界区
// 进入区代码，假设有两个进程i,j访问临界区
flag[i] = true;
turn = j;
while(flag[j]&&turn==j);	// 当进程j想进入，并且轮到j进入时，就等待，等到j不想进入或者不轮到j
// 临界区 ...
//退出区代码
flag[i] = false;
```

peterson算法执行流程（假设进程i,j交替调度执行）：

``` mermaid
graph TB
i:flagi=true --> A[j:flagj=true]
A --> B[i:turn=i]
B --> C[j:turn=j]
C --> |i:flagj=true&turn==j|D[等待]
C --> |j:flagi=true&turn!=i|E[执行临界区代码]
E --> |退出:flagj=false|D
D --> |i:flagj=false&turn==j|执行临界区代码
```

#### Dekkers算法（peterson算法的多进程版）

还是一个进程一个flag表示自己想进，一个turn改成每次`turn++%PROCESS_NUM`，环形循环轮



### 更高级的抽象方法：锁

借用操作系统支持，为进程提供同步服务，作为交互第三方，提供间接感知和调度。

通过原子操作指令直接锁定和解锁资源。`lock::Acquire()和lock::Release()`

原子操作指令：现代CPU体系结构都提供一些特殊的原子操作指令；

- 测试与置位指令(Test-and-Set，TS指令)：从内存单元读出一个值(Test)，并讲该单元写入1(Set)，然后返回读出的值(Test)，这条命令可以用与检测锁的值，并将锁置位；
- 交换指令(exchange)：交换指令，交换内存中的两个值；

#### 使用TS指令实现自旋锁(spinlock)

``` c
class Lock {
    int value = 0;	// 这是锁
    WaitQueue q;	// 等待队列，无忙等待锁用到
}
// 实现自旋锁，会占用CPU资源
Lock::Acquire(){
    while(test-and-set(value))
        ;	// spin
}
Lock::Release(){
    value = 0;
}
// 实现无忙等待锁，不占用CPU资源
Lock::Acquire(){
    while(test-and-set(value)){
        add this TCB to wait queue;	// 当前线程加入TCB，然后调度执行其他线程
        schedule();
    }
}
Lock::Release(){
    value = 0;
    remove one thread t from q;		// 当前线程退出后唤醒等待队列中等待该资源的下一个线程
    wakeup(t);
}
```

使用交换指令也能实现自旋锁或无忙等待锁

优点：

- 适用于单处理器或共享主存的多处理器中任意数量的进程同步
- 简单并容易证明正确性
- 支持多临界区

缺点：

- 忙等待消耗处理时间
- 可能导致饥饿
- 可能死锁：低优先级进程获得临界区资源，高优先级进程获得处理器并等待临界区

## 信号量与管程

### 信号量(semaphore)

定义：信号量是操作系统提供的一种协调共享资源访问的方法。

> 软件同步时线程间平等的同步协商，信号量时OS管理，地位高于进程。
>
> 信号量表示系统资源的数量。
>
> 信号量时早期操作系统的主要同步机制，目前很少用了，但在计算机科学研究中还是很重要。

信号量是一种抽象数据类型，由一个整型变量(sem)和两个原子操作组成。

- P()（Prolaag，荷兰语尝试减少）
  - sem减一
  - 若sem<0，则进入等待，否则继续
- V()（Verhoog，荷兰语增加）
  - sem加一
  - 若sem<=0，则唤醒一个等待进程

> 类似锁的整型，不止一个资源了。

信号量特性：

- 信号量是被保护的整数变量，初始化完成后只能通过PV操作修改，而OS保证PV是原子操作；
- P可能会阻塞，V不会阻塞；
- 等待队列先进先出，一般假定公平，并通过操作系统调度尽量做到公平。

信号量分类：

- 二进制信号量：资源数目为0或1

- 资源信号量：资源数目为任何非负值

  > 两者等价，基于一个可以实现另一个

信号量的使用：

- 互斥访问：临界区互斥访问控制，生产者-消费者问题
- 条件同步：线程间的事件等待

使用信号量的困难：

- 读/开发代码比较困难，程序员必须能运行信号量机制
- 容易出错，忘记释放信号量或者使用的信号量被占用导致死锁，需要考虑多个地方的流程调跳转，改时也都要改，容易出错。
- 不能处理死锁问题，必须程序员开发时解决。

### 管程(Moniter)

改进信号量在临界区处理上的问题（PV原语分在两个不同的进程，配对困难）。

管程是一种用户多线程互斥访问共享资源的程序结构

- 采用面向对象的方法，简化了线程间的同步控制；
- 任意时刻最多只有一个线程执行管程代码；
- 正在管程中的线程可以临时放弃管程的互斥访问，等待事件出现时恢复。

管程的使用：

- 在对象/模块中收集相关共享的数据；
- 在对象/模块中定义访问共享数据的方法。

管程组成：

- 一个锁：控制管程代码的互斥访问；
- 0~多个条件变量，管理共享数据的并发访问。

条件变量(Condition Variable)：

条件变量是管程内部的等待机制

- 进入管程的线程因资源而被占用进入等待状态；
- 每个条件变量表示一种等待原因，对应一个等待队列。

等待操作Wait()：

- 阻塞自身，并加入等待队列；
- 唤醒一个等待者或释放管程的互斥访问。

释放操作Signal()：

- 将等待队列中的一个线程唤醒；
- 等待队列空则空操作。

管程实现：

``` cpp
class Condition {
    int numWaiting = 0;	// 等待进程数，初值0，信号量初值为资源数。
    WaitQueue q;		// 等待队列
}
// 等待操作
Condition::Wait(lock){	// lock是锁，Lock lock;在实例中申请
    numWaiting++;
    add this thread t to q;
    lock->Release();		// 管程互斥访问
    schedule();			// 调度其他进程，等待资源，被唤醒后从这里继续往下执行。
    lock->Acquire();		// 等到管程，申请资源
}
// 释放操作
Condition::Signal(){
    if (numWaiting > 0) {		//等待队列空则空操作
        remove a thread t from q;
        wakeup(t);
        NumWaiting--;
    }
}
```

用管程解决生产者-消费者问题实例：

``` cpp
class BoundedBuffer {
    ...
    Lock lock;
    int count = 0;
    Condition notFull, notEmpty;
}
// 生产者往里放
BoundedBuffer::Deposit(c){
    lock->Acquire();			// 管程的互斥访问
    while (count == n)			// while:Hansen管程，if:Hoare管程
        notFull.Wait(&lock);	// Wait()中有调度，只有等到有资源后才会继续执行，所以不会循环多次加入等待队列，进一次Deposit只会加一个等待队列。等待notFull条件成立后继续执行。
    Add c to the buffer;
    count++;
    notEmpty.Signal();
    lock->Release();
}
// 消费者往外拿
BoundedBuffer::Remove(c){
    lock->Acquire();
    while (count == 0)
        notFull.Wait(&lock);
    Remove c from the buffer;
    count--;
    notFull.Signal();
    lock->Release();
}
```

管程条件变量的释放处理方式

1. Hansen管程：主要用户真是OS和Java，切换次数较少，效率较高
   1. 进程T1先进入管程开始执行，执行到等待资源x时；
   2. 进程T2开始执行，执行到释放资源x后，继续执行到退出管程；
   3. 进程T1获取资源继续执行。
2. Hoare管程：确定性较好，主见于教材
   1. 进程T1先进入管程开始执行，执行到等待资源x时；
   2. 进程T2开始执行，执行到释放资源x后，等待；
   3. T1获取资源继续执行继续执行到退出管程；
   4. 进程T2继续执行到退出管程。

## 死锁(Deadlock)

### 死锁的定义、分类与产生条件

死锁是指几个进程各自占用部分资源，都不够完成工作，都不释放，陷入死循环等待。

进程访问资源的流程：请求/获取  -> 使用/占用 -> 释放。

资源分类：

- 可重用资源(Reusable Resource)：资源不能被删除且在任何时刻只能由一个进程使用；进程释放资源后，其他进程可重用。例如：CPU，I/O通道，存储器，外设，文件，数据库，信号量等数据结构。
  - 死锁原因：占用一部分资源并请求另一部分。
- 消耗资源(Consumable Resource)：资源会被创建和销毁，例如I/O缓冲区的中断、信号、消息等；
  - 死锁原因：进程间互相等待对方消息；

出现死锁的必要条件：

- 互斥：任何时刻只能由一个进程使用一个资源实例；
- 持有并等待：进程持有至少一种资源并等待其他资源；
- 非抢占：资源只能由进程使用后自愿放弃；
- 循环等待：资源使用图中存在等待循环。

>  ***实际应用中死锁由应用进程处理，通常操作系统忽略死锁的存在。也就是说死锁要由程序员在编程时考虑并处理***

### 死锁的处理方法

#### 死锁预防(Deadlock Prevention)

确保系统用于不会进入死锁，但是这样系统资源利用效率比较低。

使系统在任何时刻都不满足死锁的必要条件：

- 互斥：把互斥的共享资源封装成可同时访问的（由被访问的资源协调访问者的使用先后，对外表现为可同时访问，例如打印机：多台电脑可以推送资源过来，打印机自行决定打印先后顺序）；
- 持有并等待：进程请求资源时，要求不持有其他任何资源（需要的资源必须一次性申请到，不允许申请到一部分再申请另一部分）；或者在进程开始执行时申请所有需要的资源。缺点：资源利用率低；
- 非抢占：如果进程请求不能立即分配的资源，则释放已占有的资源；
- 循环等待：对资源排序，要求进程按顺序请求资源；也会资源利用率低。

#### 死锁避免(Deadlock Avoidance)：银行家算法

严格审批资源的申请，只允许不会出现死锁的进程请求资源。利用额外的先验信息，在分配资源时判断是否会出现死锁，只在不会死锁时分配资源。

要求进程事先声明需要资源的最大数目，限定提供与分配资源的数量，确保满足进程最大需求，不能满足就不分配。动态检查资源分配状态（资源分配符），确保不会出现环形等待：真怼当前分配资源情况，维护一个安全序列，确保系统处于安全状态运行，不安全则不分配资源。

银行家算法：

- 银行家：操作系统， 资金：资源， 客户：申请资源的线程；

- 客户第一次申请贷款时，声明所需最大资金量，在满足所有贷款要求并完成项目时及时归还；银行家在客户贷款数量不超过银行拥有最大值时，应尽量满足客户需要；

- 银行家算法数据结构：设线程数量n，资源类型数量m；则由如下数据结构需要维护：

  - 总需求量(Max)：n*m的矩阵，线程Ti最多申请Rj的资源Max[i,j]个实例，矩阵第i行表示线程i所需的j项资源各自的数量；
  - 剩余空闲量(Available)：长度为m的向量，当前有剩余的空闲Available[j]个类型Rj的资源实例可用，一个元素表示Rj号资源还剩余i个；
  - 已分配量(Allocation)：n*m的矩阵，线程Ti当前分配了Allocation[i,j]个资源实例，解释同Max；
  - 未来需要量(Need)：n*m的矩阵，线程Ti未来需要Need[i,j]个资源实例，解释同Max
  - Need[i,j] = Max[i,j] - Allocation[i,j];

- 安全状态判断：

  1. 遍历当前分配出去资源的所有线程Ti (i=1~n)；
  2. 寻找一个线程Ti，判断其未来需要量，是否能够用剩余空闲量满足（Need[i]<=Available），如果能满足，转3；
  3. 如果能满足则将该线程的状态改为完成，并回收资源到Available，然后继续判断其他线程，转2；
  4. 知道所有线程的状态都变为完成，则说明当前状态安全，并找到了一个安全队列，通过先后执行安全队列里的线程，能够使所有线程完成，回收全部资源；

  > 总的来说，就是从全部贷款的线程中，找到一个当前就能满足未来需求量的线程，给其资源，让其执行完成，完成后回收资源找下一个能满足未来需求量的线程，继续重复操作，直到完成所有线程，回收所有资源，根据完成先后，得到一个安全队列，证明状态安全；或者卡在某处，剩余资源量不足以满足剩下任何线程的需求，则说明当前状态不安全。

- 银行家算法执行：

  - 数据：线程Ti申请资源向量Requesti，Requesti是一个向量，请求j项资源

  1. 判断Requesti <= Needi，不是则拒绝申请，因为该线程超过了当初承诺需要的最大量了；
  2. 判断Requesti <= Available，不是则要等待，因为资源不够；
  3. （通过安全状态判断是否分配资源给Ti）生成一个分配资源后的状态，调用前面的安全状态判断函数，判断当前状态是否安全，安全则分配，不安全则拒绝；

#### 死锁检测与恢复(Deadlock Detection & Recovery)

检测到运行系统进入死锁状态后进行恢复。

允许系统进入死锁状态，维护系统的资源分配图。定期调用死锁检测算法搜索图中是否存在死锁，存在则调用死锁恢复机制进行恢复。

死锁检测算法（与银行家算法的安全检测相似，但没有Max的判断）：

- 数据结构：

  - Available：长度为m的向量，每种类型可用资源的数量；
  - Allocation：一个n*m矩阵，当前分配给各个进程每种资源的数量，进程Pi拥有资源Ri的Allocation[i,j]个实例。

- 死锁检测算法

  1. 找到一个线程Ti，使得Requesti<=Available；
  2. Ti状态改为完成，并回收所有资源，重复步骤1；
  3. 当所有线程都能完成则没有死锁，否则就是死锁了。

  > 算法时间复杂度为：$O(m{\times}n^2)$，开销很大，所以操作系统不管死锁的事情。

死锁检测时间和周期的选择：死锁多久可能会发生，多少进程需要被回滚；

资源图可能有多个循环，难以分辨造成死锁的关键进程；

死锁恢复：进程终止的选择

- 终止所有死锁进程
- 依次之中之一个进程直到死锁消除
- 终止进程的顺序
  1. 进程的优先级：先终止优先级最低的；
  2. 进程已运行时间以及还需运行的时间：执行时间长的希望能留下来；
  3. 进程已占用资源
  4. 进程完成需要的资源
  5. 终止进程数目：越小越好
  6. 进程使前台交互进程还是批处理进程：希望交互进程能继续处理，而终止批处理进程

死锁恢复：资源抢占

- 选择被抢占的进程：选成本最小的目标；
- 进程回退：返回到一些安全状态，重启进程到安全状态；
- 可能出现饥饿：同一个进程可能一直被选作抢占者。

## 进程通信(又称进程间通信，IPC，Inter-process Communication)

### 定义与通信方式、链路概念

定义：进程通信时进程进行通信和同步的机制

IPC提供2个基本操作

- 发送操作：send(message)
- 接收操作：receive(message)

进程通信流程

- 在通信进程间建立通信链路
- 通过send/receive交换消息

进程链路特征

- 物理（如，共享内存，硬件总线）
- 逻辑（如，逻辑属性的设置不同）

通信方式

- 间接通信：两个进程通过内核通信，内核做中转
  - 通过操作系统维护的消息队列实现进程间的消息接收和发送；
  - 每个消息队列都有一个唯一的标识；
  - 只有共享了相同消息队列的进程才能建立链接并通信，通过该方式能实现进程通信的保密性；
  - 连接可以是单向或双向的；
  - 消息队列可以与多个进程相关联，每对进程可以共享多个消息队列
  - 消息队列创建流程：1. 创建消息队列；2. 通过消息队列通信；3. 销毁消息队列；
  - 基本通信操作：发送消息到消息队列，从消息队列接收消息，不关心对方是谁，只关心哪个队列。
- 直接通信：两个进程间建立通信信道（共享信道）
  - 发送和接收操作中，进程必须正确命名对方，发送给进程，从某进程接收
  - 每对进程间只有一个链路存在，一条链路对应一对通信进程
  - 链路时自动建立的
  - 链路可以时单向的，但通常是双向的
- 阻塞（同步）通信：每一次通信都必须成功，否则阻塞
  - 阻塞发送：发送者发送后进入等待，直到接收方收到；
  - 阻塞接收：接收者在请求接收消息后进入等待，直到收到一个消息；
- 非阻塞（异步）通信
  - 非阻塞发送：发送者发送后立刻进行其他操作，不管对方收到没；
  - 非阻塞接收：没有消息消息发送时，接收者在请求接收消息后，接收不到任何消息，就去干别的了；

通信链路缓冲：根据链路上是否存在消息缓存，可分为三种缓冲方式

- 0容量：发送方必须等待接收方接收；
- 有限容量：通信链路缓冲队列满时，发送方必须等待；
- 无限容量：发送房不需要等待；

### 通信方式实现

操作系统提供两种简单的通信机制：信号与管道

四种进程间通信方式都需要经过内核，由内核提供系统调用：信号、管道、消息队列、共享内存；

#### 信号

信号：进程间的软件中断通知和处理机制（系统中中断机制扩展到进程中就是信号）。例如：Ctrl-C是一个SIGKILL信号。signal(SIGKILL, fun)。

信号的接受处理：

- 捕获(Catch)：执行指定的信号处理函数被调用
- 忽略(Ignore)：执行操作系统指定的缺省处理，例如Ctrl-C：终止进程
- 屏蔽(Mask)：禁止进程接收和处理信号，可能是在适当的时候暂时屏蔽，例如登录时暂时屏蔽Ctrl-C

信号的缺点：传送信息量小，只有一个信号类型

> 作为快速响应机制，比别的通信机制快。

信号的实现：

1. 注册：进程启动时，注册信号处理函数，以便于操作系统收到信号后直到去执行哪个信号处理函数；
2. 其他进程或设备发出信号时，操作系统接收并把信号送给指定的进程并启动其中的信号处理函数；
3. 执行信号处理函数。

与信号相关的系统调用：

- signal(sig, fun);注册信号处理程序。

#### 管道

管道：进程间基于内存文件的通信机制。两个进程想通信，就在内存中建一个临时文件用于存放通信数据，这个内存中断临时文件就是管道。

子进程从父进程继承文件描述符（缺省文件描述符：0 stdin, 1 stdout, 2 stderr)。

进程不知道（或不关心）管道的另一头是谁，只关心是哪个管道。另一头可能是键盘、文件、程序读取，也可能写入终端、文件、程序。

与管道相关的系统调用：

- 读管道：`read(fd,buffer,nbytes);`scanf()基于read实现；
- 写管道：`write(fd,buffer,nbytes);`printf()基于write实现
- 创建管道：pipe(rgfd)，rgfd是两个文件描述符组成的数组，rgfd[0]是读文件描述符，rgfd[1]是写文件描述符。利用继承关系，在两个不同的进程中使用不同的文件描述符，读对写，写对读，即可通信。

实例：`ls | more`：

1. shell解释“|”为管道，并为ls和more创建了一个管道；
2. shell创建进程ls，并将ls的stdout接入管道，作为写端；
3. shell创建进程more，并将more的stdin接入管道，作为读端。

#### 消息队列

消息队列时由操作系统内核维护的以字节序列为基本单位的间接通信机制。

每个消息(Message)是一个字节序列，相同标识的消息组成按先进先出顺序组成消息队列(Message Queues)。

与消息队列相关的系统调用；

- msgget(key, flags)：获取消息队列标识，

- msgsnd(QID, buf, size, flags)：消息发送，入参有缓冲区起始地址，缓冲区大小，标识

- msgrcv(QID, buf, size, type, flags)：接受消息

- msgctl(…)：消息队列控制（创建和删除消息队列）。

  >  消息队列在进程结束时不会被销毁，由此可以实现不同生命周期进程间的通信。

#### 共享内存

共享内存是把同一个物理内存区域同时映射到多个进程的内存地址空间的通信机制。

进程：

- 每个进程都有私有内存地址空间；
- 每个进程的内存地址空间需明确设置共享内存段；

线程：

- 同一个进程中的线程总是共享相同的内存地址空间；

优点：快速、方便的共享数据，是最快的方法，一个进程写入另一个进程立即可见，没有系统干预，没有数据复制。

不足：仅靠共享内存无法实现完整的通信，必须用额外的同步互斥机制来协调数据访问，由程序员提供同步。

共享内存实现：两个进程的页表项映射到同一物理内存。

共享内存相关系统调用：

- shmget(key, size, flags)：创建共享段；

- shmat(shmid, *shmaddr, flags)：把共享段映射到进程地址空间；

- shmdt(shmaddr)：取消共享段到进程地址空间的映射；

- shmctl(…)：共享段控制。

  > 共享数据的访问只需正常的读写指令(mov等)，不需要系统调用。
  >
  > 需要信号量等同步机制协调共享内存的访问冲突。